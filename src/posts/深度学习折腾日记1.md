---
title: 深度学习折腾日记（一）
description: 环境搭建
---

俗话说磨刀不误砍柴工，配置好一个良好的深度学习环境是学习的第一步， 本文将从显卡选型到环境配置一条龙讲述整个深度学习环境搭建的过程。

## 硬件选型
现在是2023年02月25日，目前的显卡市场依旧不是很好，矿卡泛滥，40系新卡又太贵，在这样的环境下要找一张好用的显卡还真不容易。不过目前确实有个很好的选择：`Tesla P40`，这是一张2016年发布的专业计算卡，属于`Pascal`架构16nm工艺，有3840个CUDA核心，24GB显存，显卡性能接近3060/1080Ti，但是显存比它们都要大，很适合如今的大规模深度学习场景。这张卡一开始的建议零售价为6000~8000美元，而现在闲鱼价格==800人民币==，对，价格缩水了接近70倍。从服务器端捡垃圾就是这样的哈哈：）

不过不是所有人都适合这张显卡，使用这张显卡的门槛还是比较高的。首先这张显卡功耗不小，大约和3060功耗差不多，我的台式机电源是`650W`，带得起P40显卡。另外由于P40是计算卡，没有视频输出，需要本身就有一张亮机卡、或者有核显，我的CPU是有核显的。最后一点需要注意的是P40显卡原本是安装在服务器里边使用的，是被动散热的，就需要比较强的风道，于是你还需要对P40显卡做一些散热改装（比如加风扇，或者改水冷）

## 安装驱动
P40显卡支持Windows和Linux，官网可以直接[下载驱动]()，使用`sh xxx.run`安装。不过并不是很推荐使用这种方式，可能会出一些差错，我选择了用包管理器安装：

参考这份[指导](https://docs.nvidia.com/datacenter/tesla/tesla-installation-notes/index.html#package-manager)就能安装上NVIDIA驱动了。安装的时候务必注意命令行提示，不要使用P40作为显卡输出，不要一路yes，不然会导致黑屏（不幸的是我就遇到了，下面我会讲如何解决）

安装成功后在命令行执行`nvidia-smi`就能看到详细的显卡信息了：
```shell
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla P40           Off  | 00000000:01:00.0 Off |                    0 |
| N/A   23C    P8     8W / 250W |     38MiB / 23040MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
 
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A     27581      G   /usr/lib/xorg/Xorg                 38MiB |
+-----------------------------------------------------------------------------+
```
另外还可以通过`cpux`查看显卡信息
![](https://picture-bed-1301848969.cos.ap-shanghai.myqcloud.com/20230225210627.png)


### 解决黑屏问题
安装驱动后重启发现linux灰屏了，整个屏幕是灰色的，Function键还能交互，但是屏幕上没有任何其他内容了。发生这种情况大概率是display manager弄坏了，或者是使用了P40的输出驱动。

虽然图形界面坏了，但我们还可以使用终端的，使用`Ctrl+Alt+F[1-6]`就可以打开tty，F7是图形界面。进入终端我们就能进行进一步处理了。首先打开`/etc/X11/`，看下里边的`xorg.conf`文件有没有修改，如果这个文件被修改，那么就是修改成了P40的视屏输出，NVIDIA会在这个文件夹里备份一个`conf`文件，把这个备份文件还原成`xorg.conf`就可以回复啦。
如果上面的方法没有用，可能就是display manager坏了，我们重新装一个就好了：
```shell
sudo apt-get install --reinstall lightdm
```
安装的时候就会出现display manager的选择界面，我们选择`lightdm`就好，然后我们把`lightdm`重启：
```shell
sudo service lightdm restart
```
执行完后切换到图形界面`Ctrl+Alt+F7`就能看到熟悉的ubuntu登录界面了。


## 安装cuda
光安装完显卡还不能运行很多软件，默认安装的12.0的cuda，这个版本的cuda很新、适配率很低，不太适合。我们考虑安装一个稍微老一点的版本：`11.2`。

进入CUDA Toolkit [下载页面](https://developer.nvidia.com/cuda-downloads)，选择适合自己的cuda版本：
![](https://picture-bed-1301848969.cos.ap-shanghai.myqcloud.com/20230225210851.png)
下面就会出现安装指令，照着抄就可以了，不过最后一步需要更改，改成`sudo apt-get -y install cuda-11-2`，这样就安装了`11.2`版本的cuda，安装位置在`usr/local/cuda-11.2`，把cuda的bin地址放到PATH环境变量，在fish中设置：
```shell
fish_add_path -g /usr/local/cuda-11.2/bin
set -Ux LD_LIBRARY_PATH /usr/local/cuda-11.2/lib64
```
设置完后source一下，然后运行`nvcc -V`查看cuda版本：
```shell
➜  cuda-11.2 nvcc -V                                         (base)
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2020 NVIDIA Corporation
Built on Mon_Nov_30_19:08:53_PST_2020
Cuda compilation tools, release 11.2, V11.2.67
Build cuda_11.2.r11.2/compiler.29373293_0
```

## 安装cuDNN
cuDNN相当于CUDA的一个升级补丁，提供了很多深度学习的优化算法，我们要使用mxNET的话，就需要这个库。参考[官方安装指导](https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html)，先安装依赖：
```shell
sudo apt-get install zlib1g
```
然后进入cuDNN[下载页面](https://developer.nvidia.com/cudnn)(选择适合自己cuda版本的)下载（需要注册一个NVIDIA的账号）库，里边是一些头文件和动态链接库。执行以下指令安装：
```shell
sudo cp cudnn-*-archive/include/cudnn*.h /usr/local/cuda-11.2/include 
sudo cp -P cudnn-*-archive/lib/libcudnn* /usr/local/cuda-11.2/lib64 
sudo chmod a+r /usr/local/cuda-11.2/include/cudnn*.h /usr/local/cuda-11.2/lib64/libcudnn*
```

## 安装NCCL
NCCL是NVIDIA Collective Communications Library的缩写，是英伟达（NVIDIA）推出的高性能GPU通信库。NCCL可在多个GPU之间进行数据通信和同步操作，mxnet同样需要这个库。
安装方式和cuDNN类似，参考[官方安装指南](https://docs.nvidia.com/deeplearning/nccl/install-guide/index.html#debian)(选择适合自己cuda版本的下载)。
11.2版本的cuda没有deb包，得和cuDNN一样下载文件然后复制：
![](https://picture-bed-1301848969.cos.ap-shanghai.myqcloud.com/20230225212256.png)
点击`O/S agnostic local installer`下载代码库，解压后执行和上面安装cuDNN相似的命令：
```shell
sudo cp nccl-*-archive/include/nccl*.h /usr/local/cuda-11.2/include 
sudo cp -P nccl-*-archive/lib/libnccl* /usr/local/cuda-11.2/lib64 
sudo chmod a+r /usr/local/cuda-11.2/include/nccl*.h /usr/local/cuda-11.2/lib64/libnccl*
```

## 安装miniconda
管理python环境是很头疼的事情，还好有miniconda帮我们建立虚拟环境。我们需要安装这个软件，进入miniconda[下载页面](https://docs.conda.io/en/latest/miniconda.html)选择适合当前python版本和系统的版本下载，下载的结果是一个shell文件，我们用bash执行它，一路yes下来就好。

注意，miniconda默认只设置了`~/.bashrc`，要在fish环境使用的话还需要执行`conda init fish`，这条指令会在`~/.config/fish/config.fish`加入相应代码把conda可执行文件暴露出来。


## 安装MXNet
进入MXNet的[安装页面](https://mxnet.apache.org/versions/1.9.1/get_started?platform=linux&language=python&processor=gpu&environ=pip&)，可以看到最新版的MXNet只支持到cuda 11.2版本，我们安装这个最新版本。

我们其实还需要安装其他一些包，我们不必要一个个安装，可以把所有依赖写到一个`yml`文件里：
```yaml
name: gluon
dependencies:
- python=3.6
- pip:
  - mxnet_cu112==1.9.1
  - d2lzh==1.0.0
  - jupyter==1.0.0
  - matplotlib==2.2.2
  - pandas==0.23.4
```
注意这里我们选择了`mxnet_cu112`版本的mxnet，这是符合本机cuda版本的。
然后执行
```shell
conda env install -f environment.yml
```
安装虚拟环境

## 验证
在虚拟环境下新建一个jupyter notebook试着从mxnet中导入`nd`:
```python
from mxnet import nd
```
如果这条语句能够顺利执行，就说明环境配置成功。